{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10950337,"sourceType":"datasetVersion","datasetId":6811406}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/mango-data/Mango_leaf_disease1'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\nprint(\"hello\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T13:18:19.384495Z","iopub.execute_input":"2025-03-30T13:18:19.384678Z","iopub.status.idle":"2025-03-30T13:18:23.633935Z","shell.execute_reply.started":"2025-03-30T13:18:19.384659Z","shell.execute_reply":"2025-03-30T13:18:23.633151Z"}},"outputs":[{"name":"stdout","text":"hello\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the VGG16 model without the top (fully connected) layers\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Freeze all convolutional layers\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\n\n# Flatten the output of the convolutional base\nx = Flatten()(base_model.output)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)  # Add dropout to reduce overfitting\nx = Dense(8, activation='softmax')(x)  # 8-class classification\n\n# Create the new model\nmodel = Model(inputs=base_model.input, outputs=x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer='adam', \n    loss='categorical_crossentropy',  # Multi-class classification\n    metrics=['accuracy']\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define ImageDataGenerator (for rescaling)\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load Training Data\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/mango-data/Mango_leaf_disease1/train',   # Path to train folder\n    target_size=(224, 224), \n    batch_size=32,\n    class_mode='categorical'  # Multi-class classification (8 classes)\n)\n\n# Load Validation Data\nval_generator = val_datagen.flow_from_directory(\n    '/kaggle/input/mango-data/Mango_leaf_disease1/val',   # Path to validation folder\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\n# Load Test Data (For final evaluation)\ntest_generator = test_datagen.flow_from_directory(\n    '/kaggle/input/mango-data/Mango_leaf_disease1/test',   # Path to test folder\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False   # No shuffling for test set\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train the Model\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=10\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Training & Validation Accuracy\nplt.figure(figsize=(8, 5))\nplt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training vs. Validation Accuracy')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_generator)\nprint(f\"Test accuracy: {test_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.models as torch_models\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as transforms\n\n# Directories\ntrain_dir = \"/kaggle/input/mango-data/Mango_leaf_disease1/train\"\nvalid_dir = \"/kaggle/input/mango-data/Mango_leaf_disease1/val\"\nimg_size = (224, 224)\nbatch_size = 32\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Dataset and DataLoader\ntrain_dataset = ImageFolder(root=train_dir, transform=transform)\nvalid_dataset = ImageFolder(root=valid_dir, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\nnum_classes = len(train_dataset.classes)\n\ndef train_torch_model(model, model_name):\n    \"\"\"Train and fine-tune a PyTorch model.\"\"\"\n    model = model.to(device)\n\n    if hasattr(model, 'fc'):\n        model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)\n    elif hasattr(model, 'classifier'):\n        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n    \n    model.train()\n    for epoch in range(5):\n        running_loss = 0.0\n        correct, total = 0, 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        accuracy = 100 * correct / total\n        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n    \n    torch.save(model.state_dict(), f\"{model_name}.pth\")\n    print(f\"Model saved: {model_name}.pth\")\n\ndef evaluate_model(model, model_name):\n    \"\"\"Evaluate the model using accuracy, precision, recall, and F1-score.\"\"\"\n    model = model.to(device)\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for images, labels in valid_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(predicted.cpu().numpy())\n    \n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='macro')\n    recall = recall_score(y_true, y_pred, average='macro')\n    f1 = f1_score(y_true, y_pred, average='macro')\n    \n    print(f\"{model_name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n\n# Train models\nmodels = {\n    \"VGG19\": torch_models.vgg19(pretrained=True),\n    \"ResNet152\": torch_models.resnet152(pretrained=True),\n    \"AlexNet\": torch_models.alexnet(pretrained=True),\n    \"GoogleNet\": torch_models.googlenet(pretrained=True)\n}\n\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    train_torch_model(model, name)\n    evaluate_model(model, name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-30T13:20:21.427458Z","iopub.execute_input":"2025-03-30T13:20:21.427825Z","iopub.status.idle":"2025-03-30T13:29:30.326416Z","shell.execute_reply.started":"2025-03-30T13:20:21.427793Z","shell.execute_reply":"2025-03-30T13:29:30.325337Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n100%|██████████| 548M/548M [00:02<00:00, 238MB/s] \n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n100%|██████████| 230M/230M [00:01<00:00, 206MB/s] \n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n100%|██████████| 233M/233M [00:01<00:00, 201MB/s] \n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n100%|██████████| 49.7M/49.7M [00:00<00:00, 225MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Training VGG19...\nEpoch 1, Loss: 0.2733, Accuracy: 90.68%\nEpoch 2, Loss: 0.0697, Accuracy: 98.25%\nEpoch 3, Loss: 0.0061, Accuracy: 99.82%\nEpoch 4, Loss: 0.0602, Accuracy: 98.32%\nEpoch 5, Loss: 0.1008, Accuracy: 97.46%\nModel saved: VGG19.pth\nVGG19 - Accuracy: 0.9925, Precision: 0.9926, Recall: 0.9925, F1-score: 0.9925\nTraining ResNet152...\nEpoch 1, Loss: 0.2004, Accuracy: 94.79%\nEpoch 2, Loss: 0.0154, Accuracy: 99.68%\nEpoch 3, Loss: 0.0365, Accuracy: 99.07%\nEpoch 4, Loss: 0.0241, Accuracy: 99.25%\nEpoch 5, Loss: 0.0047, Accuracy: 99.93%\nModel saved: ResNet152.pth\nResNet152 - Accuracy: 0.9950, Precision: 0.9950, Recall: 0.9950, F1-score: 0.9950\nTraining AlexNet...\nEpoch 1, Loss: 0.2444, Accuracy: 91.61%\nEpoch 2, Loss: 0.0300, Accuracy: 99.07%\nEpoch 3, Loss: 0.0188, Accuracy: 99.43%\nEpoch 4, Loss: 0.0218, Accuracy: 99.57%\nEpoch 5, Loss: 0.0113, Accuracy: 99.57%\nModel saved: AlexNet.pth\nAlexNet - Accuracy: 0.9938, Precision: 0.9940, Recall: 0.9938, F1-score: 0.9938\nTraining GoogleNet...\nEpoch 1, Loss: 0.5993, Accuracy: 89.86%\nEpoch 2, Loss: 0.0479, Accuracy: 99.79%\nEpoch 3, Loss: 0.0210, Accuracy: 99.86%\nEpoch 4, Loss: 0.0133, Accuracy: 99.93%\nEpoch 5, Loss: 0.0144, Accuracy: 99.93%\nModel saved: GoogleNet.pth\nGoogleNet - Accuracy: 0.9962, Precision: 0.9964, Recall: 0.9963, F1-score: 0.9963\n","output_type":"stream"}],"execution_count":2}]}